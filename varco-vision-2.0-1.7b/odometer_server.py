"""
ì£¼í–‰ê±°ë¦¬(ODO) ê°ì§€ FastAPI ì„œë²„
- ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œ
- ì´ë¯¸ì§€ ì—…ë¡œë“œë¡œ ì£¼í–‰ê±°ë¦¬ ê°ì§€
"""

import torch
import os
import time
import json
import re
import io
from pathlib import Path
from contextlib import asynccontextmanager
from typing import Optional

from PIL import Image, ImageDraw, ImageFont
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import uvicorn

# ============ SSL ê²€ì¦ ë¹„í™œì„±í™” (í•„ìš”ì‹œ) ============
os.environ["HF_HUB_DISABLE_SSL_VERIFICATION"] = "1"

import requests
_old_request = requests.sessions.Session.request
def _new_request(self, method, url, **kwargs):
    kwargs["verify"] = False
    return _old_request(self, method, url, **kwargs)
requests.sessions.Session.request = _new_request

# ============ ì„¤ì • ============
SNAPSHOT_PATH = "/root/.cache/huggingface/hub/models--NCSOFT--VARCO-VISION-2.0-1.7B/snapshots/ed09f37445518b1564d1ef3c6e26fbd7c1b2c818"

# ============ ì „ì—­ ë³€ìˆ˜ ============
model = None
processor = None


# ============ Pydantic ëª¨ë¸ ============
class OdometerResult(BaseModel):
    odometer_value: Optional[str] = None
    unit: Optional[str] = None
    bounding_box: Optional[list] = None
    confidence: Optional[float] = None
    raw_output: str
    inference_time: float
    tokens_generated: int
    tokens_per_sec: float


class HealthResponse(BaseModel):
    status: str
    model_loaded: bool
    gpu_available: bool
    gpu_memory_used: Optional[float] = None


# ============ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ============
def parse_json_from_output(output: str) -> dict | None:
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ JSON íŒŒì‹±"""
    patterns = [
        r'```json\s*(.*?)\s*```',
        r'```\s*(.*?)\s*```',
        r'(\{[^{}]*\})',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, output, re.DOTALL)
        if match:
            try:
                return json.loads(match.group(1))
            except json.JSONDecodeError:
                continue
    
    try:
        return json.loads(output)
    except json.JSONDecodeError:
        return None


def draw_bbox_on_image(image: Image.Image, bbox: list, label: str = "") -> Image.Image:
    """ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°"""
    image = image.copy()
    draw = ImageDraw.Draw(image)
    
    x_min, y_min, x_max, y_max = bbox
    img_width, img_height = image.size
    
    # ============ ì •ê·œí™”ëœ ì¢Œí‘œ(0~1)ë¥¼ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜ ============
    if all(0 <= v <= 1 for v in bbox):
        x_min = int(x_min * img_width)
        y_min = int(y_min * img_height)
        x_max = int(x_max * img_width)
        y_max = int(y_max * img_height)
    else:
        x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)
    
    # ì„  ë‘ê»˜: ì´ë¯¸ì§€ í¬ê¸°ì— ë¹„ë¡€ (ë” ì˜ ë³´ì´ê²Œ)
    line_width = max(4, int(min(img_width, img_height) * 0.006))
    
    # ëˆˆì— ë„ëŠ” ìƒ‰ìƒ (ë°ì€ ë…¹ìƒ‰)
    box_color = (0, 255, 0)
    
    # ë°•ìŠ¤ ê·¸ë¦¬ê¸°
    draw.rectangle([x_min, y_min, x_max, y_max], outline=box_color, width=line_width)
    
    if label:
        try:
            font_size = max(24, int(min(img_width, img_height) * 0.03))
            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
        except:
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", font_size)
            except:
                font = ImageFont.load_default()
        
        text_y = y_min - font_size - 8
        if text_y < 0:  # ìœ„ì— ê³µê°„ ì—†ìœ¼ë©´ ì•„ë˜ì— í‘œì‹œ
            text_y = y_max + 4
        
        text_bbox = draw.textbbox((x_min, text_y), label, font=font)
        draw.rectangle(text_bbox, fill=box_color)
        draw.text((x_min, text_y), label, fill=(0, 0, 0), font=font)
    
    return image


def get_prompt() -> str:
    """ì£¼í–‰ê±°ë¦¬ ê°ì§€ìš© í”„ë¡¬í”„íŠ¸"""
    return """ì´ ìë™ì°¨ ê³„ê¸°íŒ ì´ë¯¸ì§€ì—ì„œ ì´ ì£¼í–‰ê±°ë¦¬(ODO/ì£¼í–‰ì ì‚°ê³„)ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

âš ï¸ ì¤‘ìš”í•œ êµ¬ë¶„:
- ì´ ì£¼í–‰ê±°ë¦¬ (ODO): ì°¨ëŸ‰ì´ ì§€ê¸ˆê¹Œì§€ "ì£¼í–‰í•œ" ëˆ„ì  ê±°ë¦¬ (ì˜ˆ: 45,230 km)
- ì£¼í–‰ê°€ëŠ¥ê±°ë¦¬ (DTE): ë‚¨ì€ ì—°ë£Œë¡œ "ì•ìœ¼ë¡œ ê°ˆ ìˆ˜ ìˆëŠ”" ê±°ë¦¬ (ì˜ˆ: 350 km)
- íŠ¸ë¦½ë¯¸í„° (TRIP): êµ¬ê°„ë³„ ì£¼í–‰ê±°ë¦¬

â†’ "ì£¼í–‰ê°€ëŠ¥ê±°ë¦¬"ë‚˜ "TRIP"ì´ ì•„ë‹Œ, "ì´ ì£¼í–‰ê±°ë¦¬(ODO)"ë§Œ ì°¾ì•„ì£¼ì„¸ìš”.

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
{
    "odometer_value": "ìˆ«ìê°’",
    "unit": "km ë˜ëŠ” miles",
    "bounding_box": [x_min, y_min, x_max, y_max],
    "confidence": 0.0~1.0
}

íŒíŠ¸:
- ODO, TOTAL, ì£¼í–‰ê±°ë¦¬ ë¼ë²¨ ê·¼ì²˜ë¥¼ í™•ì¸í•˜ì„¸ìš”
- ì£¼í–‰ê°€ëŠ¥ê±°ë¦¬ëŠ” ë³´í†µ ì—°ë£Œ ê²Œì´ì§€ ê·¼ì²˜ì— í‘œì‹œë©ë‹ˆë‹¤
- ì´ ì£¼í–‰ê±°ë¦¬ëŠ” ë³´í†µ 5~6ìë¦¬ ì´ìƒì˜ í° ìˆ«ìì…ë‹ˆë‹¤"""


# ============ ëª¨ë¸ ë¡œë”© ============
def load_model():
    """ëª¨ë¸ê³¼ í”„ë¡œì„¸ì„œ ë¡œë“œ"""
    global model, processor
    
    from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration
    
    print("=" * 50)
    print("ğŸš€ ëª¨ë¸ ë¡œë”© ì¤‘...")
    start_time = time.perf_counter()
    
    model = LlavaOnevisionForConditionalGeneration.from_pretrained(
        SNAPSHOT_PATH,
        local_files_only=True,
        device_map="auto",
        torch_dtype="auto",
    )
    processor = AutoProcessor.from_pretrained(SNAPSHOT_PATH, local_files_only=True)
    
    load_time = time.perf_counter() - start_time
    print(f"âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ! ({load_time:.2f}ì´ˆ)")
    print("=" * 50)
    
    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            allocated = torch.cuda.memory_allocated(i) / (1024 ** 3)
            print(f"  GPU {i} ë©”ëª¨ë¦¬ ì‚¬ìš©: {allocated:.2f} GB")


# ============ FastAPI ì•± ì„¤ì • ============
@asynccontextmanager
async def lifespan(app: FastAPI):
    """ì„œë²„ ì‹œì‘/ì¢…ë£Œ ì‹œ ì‹¤í–‰"""
    # ì‹œì‘ ì‹œ: ëª¨ë¸ ë¡œë“œ
    load_model()
    yield
    # ì¢…ë£Œ ì‹œ: ì •ë¦¬ (í•„ìš”ì‹œ)
    print("ì„œë²„ ì¢…ë£Œ ì¤‘...")


app = FastAPI(
    title="ì£¼í–‰ê±°ë¦¬ ê°ì§€ API",
    description="ìë™ì°¨ ê³„ê¸°íŒ ì´ë¯¸ì§€ì—ì„œ ì£¼í–‰ê±°ë¦¬(ODO)ë¥¼ ê°ì§€í•˜ëŠ” API",
    version="1.0.0",
    lifespan=lifespan
)


# ============ API ì—”ë“œí¬ì¸íŠ¸ ============
@app.get("/health", response_model=HealthResponse)
async def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    gpu_memory = None
    if torch.cuda.is_available():
        gpu_memory = torch.cuda.memory_allocated(0) / (1024 ** 3)
    
    return HealthResponse(
        status="healthy",
        model_loaded=model is not None,
        gpu_available=torch.cuda.is_available(),
        gpu_memory_used=gpu_memory
    )


@app.post("/detect", response_model=OdometerResult)
async def detect_odometer(
    image: UploadFile = File(..., description="ê³„ê¸°íŒ ì´ë¯¸ì§€ íŒŒì¼")
):
    """
    ì£¼í–‰ê±°ë¦¬ ê°ì§€ (JSON ê²°ê³¼ ë°˜í™˜)
    
    - ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ì£¼í–‰ê±°ë¦¬ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜
    """
    if model is None or processor is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        contents = await image.read()
        pil_image = Image.open(io.BytesIO(contents)).convert("RGB")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    # ì¶”ë¡  ì¤€ë¹„
    prompt = get_prompt()
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": pil_image},
                {"type": "text", "text": prompt},
            ],
        },
    ]
    
    # ì „ì²˜ë¦¬
    inputs = processor.apply_chat_template(
        conversation,
        add_generation_prompt=True,
        tokenize=True,
        return_dict=True,
        return_tensors="pt"
    ).to(model.device, torch.float16)
    
    # ì¶”ë¡ 
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    
    inference_start = time.perf_counter()
    
    with torch.no_grad():
        generate_ids = model.generate(**inputs, max_new_tokens=1024)
    
    if torch.cuda.is_available():
        torch.cuda.synchronize()
    
    inference_time = time.perf_counter() - inference_start
    
    # í›„ì²˜ë¦¬
    generate_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generate_ids)
    ]
    output = processor.decode(generate_ids_trimmed[0], skip_special_tokens=True)
    
    num_tokens = len(generate_ids_trimmed[0])
    tokens_per_sec = num_tokens / inference_time if inference_time > 0 else 0
    
    # JSON íŒŒì‹±
    parsed = parse_json_from_output(output)
    
    return OdometerResult(
        odometer_value=parsed.get("odometer_value") if parsed else None,
        unit=parsed.get("unit") if parsed else None,
        bounding_box=parsed.get("bounding_box") if parsed else None,
        confidence=parsed.get("confidence") if parsed else None,
        raw_output=output,
        inference_time=round(inference_time, 3),
        tokens_generated=num_tokens,
        tokens_per_sec=round(tokens_per_sec, 2)
    )


@app.post("/detect/visualize")
async def detect_and_visualize(
    image: UploadFile = File(..., description="ê³„ê¸°íŒ ì´ë¯¸ì§€ íŒŒì¼")
):
    """
    ì£¼í–‰ê±°ë¦¬ ê°ì§€ + ì‹œê°í™” (ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê·¸ë ¤ì§„ ì´ë¯¸ì§€ ë°˜í™˜)
    
    - ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ ë°”ìš´ë”© ë°•ìŠ¤ê°€ í‘œì‹œëœ ì´ë¯¸ì§€ë¥¼ ë°˜í™˜
    """
    if model is None or processor is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        contents = await image.read()
        pil_image = Image.open(io.BytesIO(contents)).convert("RGB")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    # ì¶”ë¡  ì¤€ë¹„
    prompt = get_prompt()
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": pil_image},
                {"type": "text", "text": prompt},
            ],
        },
    ]
    
    # ì „ì²˜ë¦¬ ë° ì¶”ë¡ 
    inputs = processor.apply_chat_template(
        conversation,
        add_generation_prompt=True,
        tokenize=True,
        return_dict=True,
        return_tensors="pt"
    ).to(model.device, torch.float16)
    
    with torch.no_grad():
        generate_ids = model.generate(**inputs, max_new_tokens=1024)
    
    generate_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generate_ids)
    ]
    output = processor.decode(generate_ids_trimmed[0], skip_special_tokens=True)
    
    # JSON íŒŒì‹± ë° ì‹œê°í™”
    parsed = parse_json_from_output(output)
    
    if parsed and "bounding_box" in parsed:
        bbox = parsed["bounding_box"]
        odometer_value = parsed.get("odometer_value", "")
        unit = parsed.get("unit", "")
        label = f"ODO: {odometer_value} {unit}"
        
        result_image = draw_bbox_on_image(pil_image, bbox, label)
    else:
        result_image = pil_image
    
    # ì´ë¯¸ì§€ë¥¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜
    img_byte_arr = io.BytesIO()
    result_image.save(img_byte_arr, format='PNG')
    img_byte_arr.seek(0)
    
    headers = {
        "X-Odometer-Value": "" if not parsed else parsed.get("odometer_value", ""),
        "X-Odometer-Unit": "" if not parsed else parsed.get("unit", ""),
        "X-Raw-Output": (output or "").replace("\n", " ")[:500],
    }

    # ì¤‘ìš”: í—¤ë” ê°’ì€ ë¬´ì¡°ê±´ strì´ì–´ì•¼ í•¨
    headers = {k: "" if v is None else str(v) for k, v in headers.items()}

    return StreamingResponse(
        img_byte_arr,
        media_type="image/png",
        headers=headers,
    )


@app.post("/detect/full")
async def detect_full(
    image: UploadFile = File(..., description="ê³„ê¸°íŒ ì´ë¯¸ì§€ íŒŒì¼"),
    return_image: bool = True
):
    """
    ì£¼í–‰ê±°ë¦¬ ê°ì§€ (JSON + Base64 ì´ë¯¸ì§€ ë°˜í™˜)
    
    - JSON ê²°ê³¼ì™€ í•¨ê»˜ ì‹œê°í™”ëœ ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ë°˜í™˜
    """
    import base64
    
    if model is None or processor is None:
        raise HTTPException(status_code=503, detail="ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì´ë¯¸ì§€ ë¡œë“œ
    try:
        contents = await image.read()
        pil_image = Image.open(io.BytesIO(contents)).convert("RGB")
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
    
    # ì¶”ë¡ 
    prompt = get_prompt()
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "image", "image": pil_image},
                {"type": "text", "text": prompt},
            ],
        },
    ]
    
    inputs = processor.apply_chat_template(
        conversation,
        add_generation_prompt=True,
        tokenize=True,
        return_dict=True,
        return_tensors="pt"
    ).to(model.device, torch.float16)
    
    inference_start = time.perf_counter()
    
    with torch.no_grad():
        generate_ids = model.generate(**inputs, max_new_tokens=1024)
    
    inference_time = time.perf_counter() - inference_start
    
    generate_ids_trimmed = [
        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generate_ids)
    ]
    output = processor.decode(generate_ids_trimmed[0], skip_special_tokens=True)
    
    num_tokens = len(generate_ids_trimmed[0])
    
    # ê²°ê³¼ êµ¬ì„±
    parsed = parse_json_from_output(output)
    
    result = {
        "odometer_value": parsed.get("odometer_value") if parsed else None,
        "unit": parsed.get("unit") if parsed else None,
        "bounding_box": parsed.get("bounding_box") if parsed else None,
        "confidence": parsed.get("confidence") if parsed else None,
        "raw_output": output,
        "inference_time": round(inference_time, 3),
        "tokens_generated": num_tokens,
    }
    
    # ì‹œê°í™” ì´ë¯¸ì§€ ì¶”ê°€
    if return_image and parsed and "bounding_box" in parsed:
        bbox = parsed["bounding_box"]
        label = f"ODO: {parsed.get('odometer_value', '')} {parsed.get('unit', '')}"
        result_image = draw_bbox_on_image(pil_image, bbox, label)
        
        img_byte_arr = io.BytesIO()
        result_image.save(img_byte_arr, format='PNG')
        img_byte_arr.seek(0)
        
        result["visualized_image_base64"] = base64.b64encode(img_byte_arr.getvalue()).decode()
    
    return JSONResponse(content=result)


# ============ ë©”ì¸ ì‹¤í–‰ ============
if __name__ == "__main__":
    uvicorn.run(
        "odometer_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,  # í”„ë¡œë•ì…˜ì—ì„œëŠ” False
        workers=1      # GPU ëª¨ë¸ì€ ë‹¨ì¼ ì›Œì»¤ ê¶Œì¥
    )
    