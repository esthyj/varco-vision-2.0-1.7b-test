import os
import time
import json
import re
import textwrap
from PIL import Image, ImageDraw, ImageFont
from vllm import LLM, SamplingParams


#### SSL verification ë¹„í™œì„±í™” ####
os.environ["HF_HUB_DISABLE_SSL_VERIFICATION"] = "1"

import requests
_old_request = requests.sessions.Session.request
def _new_request(self, method, url, **kwargs):
    kwargs["verify"] = False
    return _old_request(self, method, url, **kwargs)
requests.sessions.Session.request = _new_request
###################################


class OdometerDetectorVLLM:
    """VLLM ê¸°ë°˜ ì£¼í–‰ê±°ë¦¬ ê°ì§€ í´ë˜ìŠ¤"""
    
    _instance = None
    
    def __init__(self, model_path: str = None):
        if model_path is None:
            model_path = "/root/.cache/huggingface/hub/models--NCSOFT--VARCO-VISION-2.0-1.7B/snapshots/ed09f37445518b1564d1ef3c6e26fbd7c1b2c818"
        
        self.model_path = model_path
        self.llm = None
        self.sampling_params = None
        self.is_loaded = False
        self.load_time = 0
        
        self.prompt = textwrap.dedent("""
            ì´ ìë™ì°¨ ê³„ê¸°íŒ ì´ë¯¸ì§€ì—ì„œ ì´ ì£¼í–‰ê±°ë¦¬(ODO/ì£¼í–‰ì ì‚°ê³„)ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”.

            âš ï¸ ì¤‘ìš”í•œ êµ¬ë¶„:
            - ì´ ì£¼í–‰ê±°ë¦¬ (ODO): ì°¨ëŸ‰ì´ ì§€ê¸ˆê¹Œì§€ "ì£¼í–‰í•œ" ëˆ„ì  ê±°ë¦¬ (ì˜ˆ: 45,230 km)
            - ì£¼í–‰ê°€ëŠ¥ê±°ë¦¬ (DTE): ë‚¨ì€ ì—°ë£Œë¡œ "ì•ìœ¼ë¡œ ê°ˆ ìˆ˜ ìˆëŠ”" ê±°ë¦¬ (ì˜ˆ: 350 km)
            - íŠ¸ë¦½ë¯¸í„° (TRIP): êµ¬ê°„ë³„ ì£¼í–‰ê±°ë¦¬

            â†’ "ì£¼í–‰ê°€ëŠ¥ê±°ë¦¬"ë‚˜ "TRIP"ì´ ì•„ë‹Œ, "ì´ ì£¼í–‰ê±°ë¦¬(ODO)"ë§Œ ì°¾ì•„ì£¼ì„¸ìš”.

            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
            {
                "odometer_value": "ìˆ«ìê°’",
                "unit": "km ë˜ëŠ” miles",
                "bounding_box": [x_min, y_min, x_max, y_max],
                "confidence": 0.0~1.0
            }

            íŒíŠ¸:
            - ODO, TOTAL, ì£¼í–‰ê±°ë¦¬ ë¼ë²¨ ê·¼ì²˜ë¥¼ í™•ì¸í•˜ì„¸ìš”
            - ì£¼í–‰ê°€ëŠ¥ê±°ë¦¬ëŠ” ë³´í†µ ì—°ë£Œ ê²Œì´ì§€ ê·¼ì²˜ì— í‘œì‹œë©ë‹ˆë‹¤
            - ì´ ì£¼í–‰ê±°ë¦¬ëŠ” ë³´í†µ 5~6ìë¦¬ ì´ìƒì˜ í° ìˆ«ìì…ë‹ˆë‹¤
        """).strip()
    
    @classmethod
    def get_instance(cls, model_path: str = None):
        """ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
        if cls._instance is None:
            cls._instance = cls(model_path)
        return cls._instance
    
    def load_model(
        self,
        tensor_parallel_size: int = 1,
        gpu_memory_utilization: float = 0.9,
        max_model_len: int = 4096,
    ):
        """
        VLLM ëª¨ë¸ ë¡œë“œ
        
        Args:
            tensor_parallel_size: GPU ë³‘ë ¬í™” ìˆ˜
            gpu_memory_utilization: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            max_model_len: ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´
        """
        if self.is_loaded:
            print("âœ… ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
        
        print("=" * 50)
        print("ğŸš€ VLLM ëª¨ë¸ ë¡œë”© ì¤‘...")
        load_start = time.perf_counter()
        
        self.llm = LLM(
            model=self.model_path,
            tensor_parallel_size=tensor_parallel_size,
            gpu_memory_utilization=0.80,
            max_model_len=max_model_len,
            trust_remote_code=True,
            dtype="auto",
        )
        
        self.sampling_params = SamplingParams(
            max_tokens=1024,
            temperature=0.0,  # deterministic
            top_p=1.0,
        )
        
        load_end = time.perf_counter()
        self.load_time = load_end - load_start
        self.is_loaded = True
        
        print(f"ëª¨ë¸ ë¡œë”© ì‹œê°„: {self.load_time:.3f}ì´ˆ")
        print("=" * 50)
    
    def detect(self, image_path: str, visualize: bool = True, output_path: str = None) -> dict:
        """ë‹¨ì¼ ì´ë¯¸ì§€ ê°ì§€"""
        results = self.detect_batch([image_path], visualize=visualize)
        return results[0] if results else {}
    
    def detect_batch(
        self, 
        image_paths: list[str], 
        visualize: bool = True,
        output_dir: str = None,
    ) -> list[dict]:
        """
        ë°°ì¹˜ ì´ë¯¸ì§€ ê°ì§€ (VLLMì˜ ê°•ì !)
        
        Args:
            image_paths: ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            visualize: ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™” ì—¬ë¶€
            output_dir: ì‹œê°í™” ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
            
        Returns:
            list[dict]: ê° ì´ë¯¸ì§€ì˜ ê°ì§€ ê²°ê³¼
        """
        if not self.is_loaded:
            self.load_model()
        
        # ìœ íš¨í•œ ì´ë¯¸ì§€ë§Œ í•„í„°ë§
        valid_images = []
        valid_paths = []
        for path in image_paths:
            if os.path.exists(path):
                try:
                    img = Image.open(path).convert("RGB")
                    valid_images.append(img)
                    valid_paths.append(path)
                except Exception as e:
                    print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path} - {e}")
            else:
                print(f"âš ï¸ ì´ë¯¸ì§€ ì—†ìŒ: {path}")
        
        if not valid_images:
            return []
        
        # VLLM ì…ë ¥ ì¤€ë¹„
        inputs = []
        for img in valid_images:
            inputs.append({
                "prompt": f"<image>\nUser: {self.prompt}\nAssistant:",
                "multi_modal_data": {"image": img},
            })
        
        # ë°°ì¹˜ ì¶”ë¡ 
        print(f"ğŸ”„ ë°°ì¹˜ ì¶”ë¡  ì¤‘... ({len(inputs)}ê°œ ì´ë¯¸ì§€)")
        inference_start = time.perf_counter()
        
        outputs = self.llm.generate(inputs, self.sampling_params)
        
        inference_time = time.perf_counter() - inference_start
        print(f"ë°°ì¹˜ ì¶”ë¡  ì‹œê°„: {inference_time:.3f}ì´ˆ (í‰ê·  {inference_time/len(inputs):.3f}ì´ˆ/ì´ë¯¸ì§€)")
        
        # ê²°ê³¼ ì²˜ë¦¬
        results = []
        for i, (output, image_path) in enumerate(zip(outputs, valid_paths)):
            generated_text = output.outputs[0].text
            parsed = self._parse_json_from_output(generated_text)
            
            result = {
                "image_path": image_path,
                "raw_output": generated_text,
                "parsed": parsed,
                "inference_time": inference_time / len(inputs),  # í‰ê·  ì‹œê°„
                "num_tokens": len(output.outputs[0].token_ids),
            }
            
            # ì‹œê°í™”
            if visualize and parsed and "bounding_box" in parsed:
                if output_dir:
                    os.makedirs(output_dir, exist_ok=True)
                    base = os.path.basename(image_path)
                    name, ext = os.path.splitext(base)
                    vis_path = os.path.join(output_dir, f"{name}_result{ext}")
                else:
                    base, ext = os.path.splitext(image_path)
                    vis_path = f"{base}_result{ext}"
                
                label = f"ODO: {parsed.get('odometer_value', '')} {parsed.get('unit', '')}"
                self._visualize_bbox(image_path, parsed["bounding_box"], label, vis_path)
                result["output_image"] = vis_path
            
            results.append(result)
        
        return results
    
    def _parse_json_from_output(self, output: str) -> dict | None:
        """ëª¨ë¸ ì¶œë ¥ì—ì„œ JSON íŒŒì‹±"""
        patterns = [
            r'```json\s*(.*?)\s*```',
            r'```\s*(.*?)\s*```',
            r'(\{[^{}]*\})',
        ]
        
        for pattern in patterns:
            match = re.search(pattern, output, re.DOTALL)
            if match:
                try:
                    return json.loads(match.group(1))
                except json.JSONDecodeError:
                    continue
        
        try:
            return json.loads(output)
        except json.JSONDecodeError:
            return None
    
    def _visualize_bbox(self, image_path: str, bbox: list, label: str, output_path: str):
        """ë°”ìš´ë”© ë°•ìŠ¤ ì‹œê°í™”"""
        image = Image.open(image_path).convert("RGB")
        draw = ImageDraw.Draw(image)
        
        x_min, y_min, x_max, y_max = map(int, bbox)
        box_color = (255, 0, 0)
        draw.rectangle([x_min, y_min, x_max, y_max], outline=box_color, width=3)
        
        if label:
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/nanum/NanumGothic.ttf", 20)
            except:
                try:
                    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 20)
                except:
                    font = ImageFont.load_default()
            
            text_bbox = draw.textbbox((x_min, y_min - 25), label, font=font)
            draw.rectangle(text_bbox, fill=box_color)
            draw.text((x_min, y_min - 25), label, fill=(255, 255, 255), font=font)
        
        image.save(output_path)
        print(f"âœ… ì €ì¥: {output_path}")


def main():
    detector = OdometerDetectorVLLM.get_instance()
    
    # ëª¨ë¸ ë¡œë“œ (VLLM ì„¤ì •)
    detector.load_model(
        tensor_parallel_size=1,      # GPU ìˆ˜
        gpu_memory_utilization=0.9,  # GPU ë©”ëª¨ë¦¬ 90% ì‚¬ìš©
        max_model_len=4096,
    )
    
    # ë°°ì¹˜ ì²˜ë¦¬ (VLLMì˜ ê°•ì !)
    image_paths = [
        "../images/dashboard1.jpg",
        "../images/dashboard2.png",
        "../images/dashboard3.png",
        "../images/dashboard4.png",
    ]
    
    # í•œ ë²ˆì— ë°°ì¹˜ ì²˜ë¦¬
    print("\n" + "=" * 50)
    print("ğŸš€ VLLM ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘")
    print("=" * 50)
    
    results = detector.detect_batch(
        image_paths,
        visualize=True,
        output_dir="../images/results/",
    )
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 50)
    print("ğŸ“Š ê²°ê³¼ ìš”ì•½")
    print("=" * 50)
    
    for i, result in enumerate(results, 1):
        print(f"\n[{i}] {result['image_path']}")
        if result["parsed"]:
            print(f"    ì£¼í–‰ê±°ë¦¬: {result['parsed'].get('odometer_value')} {result['parsed'].get('unit')}")
            print(f"    ë°”ìš´ë”©ë°•ìŠ¤: {result['parsed'].get('bounding_box')}")
            print(f"    ì‹ ë¢°ë„: {result['parsed'].get('confidence')}")
        else:
            print(f"    âš ï¸ íŒŒì‹± ì‹¤íŒ¨: {result['raw_output'][:100]}...")
    
    # ì „ì²´ í†µê³„
    print("\n" + "=" * 50)
    print("ğŸ“ˆ ì „ì²´ í†µê³„")
    print("=" * 50)
    print(f"  ëª¨ë¸ ë¡œë”© ì‹œê°„: {detector.load_time:.3f}ì´ˆ")
    print(f"  ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {len(results)}ê°œ")
    if results:
        total_tokens = sum(r["num_tokens"] for r in results)
        avg_time = sum(r["inference_time"] for r in results) / len(results)
        print(f"  í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_time:.3f}ì´ˆ/ì´ë¯¸ì§€")
        print(f"  ì´ ìƒì„± í† í°: {total_tokens}ê°œ")


# API ì„œë²„ ì˜ˆì‹œ (FastAPI)
def create_api_server():
    """FastAPI ì„œë²„ ì˜ˆì‹œ"""
    from fastapi import FastAPI, UploadFile, File
    from fastapi.responses import JSONResponse
    import tempfile
    import shutil
    
    app = FastAPI(title="Odometer Detection API")
    detector = OdometerDetectorVLLM.get_instance()
    
    @app.on_event("startup")
    async def startup():
        detector.load_model()
    
    @app.post("/detect")
    async def detect_odometer(file: UploadFile = File(...)):
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp:
            shutil.copyfileobj(file.file, tmp)
            tmp_path = tmp.name
        
        try:
            result = detector.detect(tmp_path, visualize=False)
            return JSONResponse(content={
                "success": True,
                "odometer_value": result["parsed"].get("odometer_value") if result["parsed"] else None,
                "unit": result["parsed"].get("unit") if result["parsed"] else None,
                "bounding_box": result["parsed"].get("bounding_box") if result["parsed"] else None,
            })
        finally:
            os.unlink(tmp_path)
    
    return app


if __name__ == "__main__":
    main()